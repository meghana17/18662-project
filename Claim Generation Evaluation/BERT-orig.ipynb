{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT-orig.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMDsUW1DASEhtct8Ks3Hk3B"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install transformers"],"metadata":{"id":"V_MmEB6esOJ7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install sentencepiece"],"metadata":{"id":"6OySYeQ6sQ9E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install simpletransformers"],"metadata":{"id":"OjI5f5x0sTQM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install stanza"],"metadata":{"id":"s-HsNVVMsZx1"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kDZ3YECxq-fC"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import json, re\n","import time\n","import os\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import f1_score\n","import itertools\n","\n","from torch.utils.data import (\n","    Dataset, \n","    DataLoader,\n","    TensorDataset, \n","    random_split, \n","    RandomSampler, \n","    SequentialSampler)\n","\n","from transformers import (\n","    BertModel,\n","    BertForSequenceClassification,\n","    BertTokenizer,\n","    RobertaForSequenceClassification,\n","    RobertaTokenizer,\n","    AdamW,\n","    get_linear_schedule_with_warmup)\n"]},{"cell_type":"code","source":["def encode_dataframe(statement_col, target_col, unpack=False):\n","    bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","    bert_encoded_dict = statement_col.apply(lambda sent: bert_tokenizer.encode_plus(\n","                                      sent,                      \n","                                      add_special_tokens = True, \n","                                      max_length = 120,           \n","                                      pad_to_max_length = True,\n","                                      return_attention_mask = True,   \n","                                      return_tensors = 'pt',     \n","                                      truncation = True\n","                                ))\n","    bert_input_ids = torch.cat([item['input_ids'] for item in bert_encoded_dict], dim=0)\n","    bert_attention_masks = torch.cat([item['attention_mask'] for item in bert_encoded_dict], dim=0)\n","    labels = torch.tensor(target_col)\n","    sentence_ids = torch.tensor(range(len(target_col)))\n","\n","    bert_dataset = TensorDataset(sentence_ids, bert_input_ids, bert_attention_masks, labels)\n","    trial_dataset =  index_remover(bert_dataset)\n","\n","    if unpack:\n","        return bert_input_ids, bert_attention_masks, labels\n","    else:\n","        return trial_dataset"],"metadata":{"id":"El0_7xoHtA40"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def index_remover(tensordata):\n","    input_ids = []\n","    attention_masks = []\n","    labels = []\n","   \n","    for a,b,c,d in tensordata:\n","        input_ids.append(b.tolist())\n","        attention_masks.append(c.tolist())\n","        labels.append(d.tolist())\n","        \n","    input_ids = torch.tensor(input_ids)\n","    attention_masks = torch.tensor(attention_masks)\n","    labels = torch.tensor(labels)\n","    \n","    final_dataset =  TensorDataset(input_ids, attention_masks, labels)\n","    return final_dataset"],"metadata":{"id":"4YTNuEY8s-d9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"metadata":{"id":"E1z82Cm1s8bi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 32\n","epochs = 10\n","df_train = torch.load(\"/content/drive/MyDrive/18662/Project/Data/climate_train.pt\")\n","bert_train_dataloader = DataLoader(\n","            df_train,  \n","            batch_size = batch_size \n","        )"],"metadata":{"id":"No4-vWVttFZ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device(\"cpu\")\n","bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","bert_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n","                                                           num_labels = 2,\n","                                                           output_attentions = False,\n","                                                           output_hidden_states = False\n","                                                          ).to(device)\n","\n","bert_optimizer = AdamW(bert_model.parameters(), lr = 5e-5, eps = 1e-8 )\n","bert_training_stats = []\n","total_steps = len(bert_train_dataloader) * epochs\n","bert_scheduler = get_linear_schedule_with_warmup(bert_optimizer, num_warmup_steps = 0,num_training_steps = total_steps)"],"metadata":{"id":"wSnWK5D5wyFr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train():\n","    for epoch in range(0, epochs):\n","        print('Epoch {:} / {:}'.format(epoch + 1, epochs))\n","        train_loss = 0\n","        bert_model.train()\n","\n","        for step, batch in enumerate(bert_train_dataloader):\n","            input_ids = batch[0].to(device)\n","            input_mask = batch[1].to(device)\n","            labels = batch[2].to(device)\n","\n","            bert_model.zero_grad()        \n","\n","            output = bert_model(input_ids, token_type_ids=None, attention_mask=input_mask,labels=labels)\n","                                \n","            train_loss += output[0].item()\n","\n","            output[0].backward()\n","\n","            torch.nn.utils.clip_grad_norm_(bert_model.parameters(), 1.0)\n","\n","            bert_optimizer.step()\n","            bert_scheduler.step()\n","\n","        \n","        avg_train_loss = train_loss / len(bert_train_dataloader)            \n","        \n","        print(\"Average training loss: {0:.2f}\".format(avg_train_loss))\n","        bert_training_stats.append(\n","            {\n","                'epoch': epoch + 1,\n","                'Training Loss': avg_train_loss,\n","            }\n","        )\n","\n","    print(\"Training complete\")"],"metadata":{"id":"lXnAQoKMyAIP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_path = \"/content/drive/MyDrive/18662/Project/checkpoints/bert_orig/\"\n","train()\n","bert_model.save_pretrained(save_path)"],"metadata":{"id":"ZyNd-etVxySu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate(bert_dev_dataloader, bert_model):\n","    predictions = []\n","    gt = []\n","    with torch.no_grad():\n","        for step, batch in enumerate(bert_dev_dataloader):\n","            input_ids = batch[0].to(device)\n","            input_mask = batch[1].to(device)\n","            labels = batch[2].to(device)\n","            \n","            output = bert_model(input_ids, input_mask)\n","            predictions.append(output)   \n","            gt.append(labels)     \n","            \n","    predictions = torch.vstack([item[0].detach() for item in predictions])\n","    gt = [list(i.cpu().numpy()) for i in gt]\n","    gt = np.array(list(itertools.chain(*gt)))\n","\n","    return predictions, gt"],"metadata":{"id":"ouR-vHie3VY9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_dev = torch.load(\"/content/drive/MyDrive/18662/Project/Data/climate_dev.pt\")\n","bert_dev_dataloader = DataLoader(df_dev,  batch_size = batch_size)\n","\n","prediction, gt = evaluate(bert_dev_dataloader, bert_model)\n","f1 = f1_score(gt, prediction, average=None)\n","\n","print(\"F1 score for BERT-base fine-tuned on CLIMATE-FEVER:\", f1)"],"metadata":{"id":"lTXXPfW34W_b"},"execution_count":null,"outputs":[]}]}